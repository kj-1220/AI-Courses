{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key exists and begins sk-\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you reconcile the ethical implications of artificial intelligence with the potential benefits it brings to society, particularly in terms of decision-making autonomy and accountability?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - update since the videos\n",
    "\n",
    "I've updated the model names to use the latest models below, like GPT 5 and Claude Sonnet 4.5. It's worth noting that these models can be quite slow - like 1-2 minutes - but they do a great job! Feel free to switch them for faster models if you'd prefer, like the ones I use in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits involves a multifaceted approach that emphasizes ethical design, accountability, and a balanced perspective on autonomy. Here are several key aspects to consider:\n",
       "\n",
       "1. **Ethical Frameworks**: Establishing clear ethical frameworks can help guide the development and deployment of AI. This includes principles such as fairness, transparency, accountability, and respect for human rights. By integrating ethical considerations into AI design from the outset, we can address potential biases and ensure that AI systems operate in ways that are aligned with societal values.\n",
       "\n",
       "2. **Human Oversight**: Maintaining human oversight in AI decision-making processes is critical. When AI systems are used for important decisions—such as in healthcare, criminal justice, or hiring—human operators should remain involved to provide context and judgment that AI cannot replicate. This approach preserves human autonomy and ensures accountability, as humans can critique or override AI recommendations.\n",
       "\n",
       "3. **Accountability Mechanisms**: Clearly defined accountability mechanisms are essential to ensure that individuals or organizations are held responsible for AI-driven outcomes. This includes establishing liability frameworks for AI decisions and ensuring that affected parties have avenues for redress. By clarifying who is accountable, we can reinforce responsible AI usage.\n",
       "\n",
       "4. **Stakeholder Engagement**: Engaging a diverse range of stakeholders, including ethicists, policymakers, technologists, and the communities impacted by AI, can foster a more comprehensive understanding of the implications of AI. This collaboration can help identify potential risks and benefits, guiding the responsible implementation of AI technologies.\n",
       "\n",
       "5. **Education and Awareness**: Promoting education and awareness about AI among the general population can empower individuals to make informed decisions and engage critically with AI technologies. Understanding AI's capabilities and limitations can enhance public discourse around its use and encourage responsible application.\n",
       "\n",
       "6. **Balancing Innovation and Regulation**: While fostering innovation is vital for leveraging the benefits of AI, it is equally important to establish regulatory frameworks that protect individuals and society from potential harms. Effective regulation can mitigate risks associated with AI while enabling its positive contributions to areas like healthcare, environmental monitoring, and education.\n",
       "\n",
       "7. **Iterative Improvement**: The field of AI is constantly evolving, which necessitates an iterative approach to ethics and accountability. Continuous assessment of AI systems after deployment allows for the identification of unforeseen ethical issues, facilitating ongoing improvements and adaptations to changing societal norms and values.\n",
       "\n",
       "In summary, reconciling the ethical implications of AI with its benefits requires a holistic approach that involves transparent design practices, robust accountability structures, inclusive stakeholder engagement, and adaptable regulatory frameworks. By prioritizing ethical considerations alongside innovation, society can harness the potential of AI while minimizing risks and protecting decision-making autonomy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "# I've updated this with the latest model, but it can take some time because it likes to think!\n",
    "# Replace the model with gpt-4.1-mini if you'd prefer not to wait 1-2 mins\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "#model_name = \"claude-sonnet-4-5\"\n",
    "\n",
    "#claude = Anthropic()\n",
    "#response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "#answer = response.content[0].text\n",
    "\n",
    "#display(Markdown(answer))\n",
    "#competitors.append(model_name)\n",
    "#answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of artificial intelligence with its immense potential benefits, particularly concerning decision-making autonomy and accountability, is one of the most pressing challenges of our time. It requires a multi-faceted approach that prioritizes human values, proactive governance, and continuous adaptation.\n",
       "\n",
       "Here's how we can approach this reconciliation:\n",
       "\n",
       "---\n",
       "\n",
       "**1. Prioritize \"Ethics by Design\" and \"Responsible AI\" Principles:**\n",
       "\n",
       "*   **Integrate Ethical Considerations from the Outset:** Ethical principles (fairness, transparency, privacy, safety, accountability) should not be an afterthought but foundational to the AI system's design, development, and deployment.\n",
       "*   **Human-Centric AI:** Design AI to augment human capabilities, not replace human judgment, especially in critical decision-making contexts. The goal should be to empower humans, making them more effective and informed.\n",
       "\n",
       "**2. Foster Transparency and Explainability (XAI):**\n",
       "\n",
       "*   **Demystify AI Decisions:** For AI to be trusted, its decision-making processes need to be as understandable as possible. This is crucial for accountability. Where \"black box\" algorithms are used, surrogate models or post-hoc explanations can help.\n",
       "*   **Contextual Explainability:** The level of explainability required depends on the context. A recommendation engine might need less explanation than an AI system approving a loan or diagnosing a medical condition.\n",
       "*   **Traceability:** Ensure that AI decisions can be traced back to the data and logic that informed them, allowing for audits and debugging.\n",
       "\n",
       "**3. Implement Robust Human Oversight and \"Human-in-the-Loop\" Mechanisms:**\n",
       "\n",
       "*   **Varying Levels of Autonomy:** Not all AI systems need or should have full autonomy. Design systems with appropriate levels of human intervention, from \"human-on-the-loop\" (monitoring) to \"human-in-the-loop\" (approving, refining, overriding).\n",
       "*   **Critical Decision Points:** For decisions with high stakes (e.g., medical diagnoses, legal judgments, military applications), human review and final approval should be mandatory. AI acts as an assistant or recommender, not the ultimate decision-maker.\n",
       "*   **Empowering Human Judgment:** AI can process vast amounts of data and identify patterns, but humans bring contextual understanding, empathy, ethical reasoning, and the ability to handle novel situations that AI hasn't been trained on.\n",
       "\n",
       "**4. Establish Clear Accountability Frameworks:**\n",
       "\n",
       "*   **Define Responsibility:** Clearly delineate who is responsible at each stage of the AI lifecycle: the data provider, the developer, the deployer, and the user.\n",
       "*   **Algorithmic Accountability:** Develop legal and ethical frameworks that hold individuals and organizations accountable for the outcomes of AI systems, similar to how product liability works for physical goods.\n",
       "*   **Liability Models:** Explore different liability models (e.g., strict liability for high-risk AI, shared liability). This often involves extending existing legal frameworks rather than creating entirely new ones.\n",
       "*   **Independent Audits:** Mandate regular independent audits of AI systems for bias, performance, security, and adherence to ethical guidelines.\n",
       "\n",
       "**5. Address Bias and Fairness Proactively:**\n",
       "\n",
       "*   **Data Scrutiny:** Thoroughly audit training data for inherent biases (historical, societal, representation). \"Garbage in, garbage out\" is particularly true for AI.\n",
       "*   **Algorithmic Fairness Metrics:** Develop and apply metrics to measure and mitigate bias in algorithms, ensuring equitable outcomes across different demographic groups.\n",
       "*   **Continuous Monitoring:** AI systems can \"drift\" over time as they interact with new data. Continuous monitoring and retraining are essential to prevent the reintroduction or emergence of bias.\n",
       "\n",
       "**6. Develop Strong Governance and Regulatory Frameworks:**\n",
       "\n",
       "*   **International Cooperation:** AI's global nature requires international collaboration to set common standards, best practices, and potentially treaties.\n",
       "*   **Sector-Specific Regulations:** Different sectors (healthcare, finance, transportation, defense) will require tailored regulations due to their unique risks and benefits.\n",
       "*   **Standardization Bodies:** Encourage the development of technical standards for AI safety, reliability, and interoperability.\n",
       "*   **AI Ethics Boards/Committees:** Companies and governments should establish internal and external AI ethics boards to guide development, review deployments, and address concerns.\n",
       "\n",
       "**7. Foster Public Education and Dialogue:**\n",
       "\n",
       "*   **Literacy and Understanding:** Educate the public about AI's capabilities, limitations, and potential impacts to build informed trust and address misconceptions.\n",
       "*   **Participatory Design:** Involve diverse stakeholders (including affected communities) in the design and deployment process to ensure that AI systems meet societal needs and values.\n",
       "*   **Ethical Debate:** Encourage ongoing public and academic discourse on complex AI ethics issues to evolve our understanding and find solutions.\n",
       "\n",
       "**8. Invest in Research on AI Safety and Alignment:**\n",
       "\n",
       "*   **Robustness and Reliability:** Research methods to make AI systems more robust, less susceptible to adversarial attacks, and predictable in their behavior.\n",
       "*   **Value Alignment:** Invest in research to ensure that advanced AI systems are designed to align with human values and goals, especially as AI capabilities grow.\n",
       "\n",
       "---\n",
       "\n",
       "**In essence, reconciliation hinges on a dynamic balance:**\n",
       "\n",
       "*   **Embrace Benefits:** Leverage AI's power to solve complex problems, enhance human capabilities, and drive societal progress (e.g., medical breakthroughs, climate modeling, personalized education).\n",
       "*   **Mitigate Risks:** Proactively identify, understand, and address the ethical challenges, ensuring that AI serves humanity rather than undermining its values or autonomy.\n",
       "\n",
       "The goal is not to stop AI progress but to guide it responsibly, ensuring that the technology's benefits are widely shared and its risks are carefully managed through conscious design, robust governance, and a steadfast commitment to human dignity and accountability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "#model_name = \"deepseek-chat\"\n",
    "\n",
    "#response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "#answer = response.choices[0].message.content\n",
    "\n",
    "#display(Markdown(answer))\n",
    "#competitors.append(model_name)\n",
    "#answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated with the latest Open Source model from OpenAI\n",
    "\n",
    "#groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "#model_name = \"openai/gpt-oss-120b\"\n",
    "\n",
    "#response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "#answer = response.choices[0].message.content\n",
    "\n",
    "#display(Markdown(answer))\n",
    "#competitors.append(model_name)\n",
    "#answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits requires a multifaceted approach that considers both the benefits and risks associated with AI decision-making autonomy and accountability. Here are some key considerations:\n",
       "\n",
       "Benefits of AI Decision-Making Autonomy:\n",
       "\n",
       "1. Improved accuracy: AI systems can process vast amounts of data quickly and accurately, reducing errors and increasing reliability.\n",
       "2. Efficiency: AI can automate routine tasks, freeing human resources for more complex and creative work.\n",
       "3. Personalization: AI can personalize experiences, products, and services based on individual preferences and behaviors.\n",
       "\n",
       "Risks associated with AI Decision-Making Autonomy:\n",
       "\n",
       "1. Bias and discrimination: AI systems may perpetuate existing biases if they are trained on biased data, leading to unfair outcomes.\n",
       "2. Lack of transparency and accountability: AI decision-making processes can be opaque, making it difficult to understand the reasoning behind a particular decision.\n",
       "3. Dependence on data quality: AI depends on high-quality data to function effectively, which may not always be available.\n",
       "\n",
       "Addressing Ethical Implications of AI Decision-Making Autonomy:\n",
       "\n",
       "1. **Data curation and validation**: Ensure that the data used to train AI systems is accurate, representative, and unbiased.\n",
       "2. **Transparency and explainability**: Develop AI systems that provide transparent and interpretable explanations for their decision-making processes.\n",
       "3. **Human oversight and review**: Implement human oversight and review mechanisms to detect and correct errors, biases, or unintended consequences.\n",
       "4. **Regular testing and monitoring**: Regularly test and monitor AI systems for potential biases, errors, or performance degradation.\n",
       "5. **Value alignment**: Ensure that AI systems are aligned with human values, such as fairness, respect, and dignity.\n",
       "\n",
       "Accountability in AI Decision-Making:\n",
       "\n",
       "1. **Design for accountability**: Incorporate accountability into the design of AI systems, including mechanisms for auditing, testing, and evaluation.\n",
       "2. **Regulatory frameworks**: Establish regulatory frameworks that ensure companies prioritize transparency, accountability, and human oversight when developing and deploying AI systems.\n",
       "3. **Public engagement and education**: Foster public awareness of AI-related issues and promote education on AI ethics, risks, and benefits.\n",
       "\n",
       "To reconcile the ethical implications of AI with its potential benefits:\n",
       "\n",
       "1. Prioritize human values and well-being: Ensure that AI systems are designed to prioritize human values, dignity, and well-being.\n",
       "2. Encourage open communication and collaboration: Promote open communication among stakeholders, including developers, policymakers, regulators, and civil society organizations.\n",
       "3. Foster a culture of responsible innovation: Cultivate a culture of responsible innovation by prioritizing ethics, transparency, accountability, and social responsibility.\n",
       "\n",
       "Ultimately, reconciling the ethical implications of AI with its potential benefits requires a proactive and multistakeholder approach that balances technological progress with social responsibility and human well-being."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'gemini-2.5-flash', 'llama3.2']\n",
      "[\"Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits involves a multifaceted approach that emphasizes ethical design, accountability, and a balanced perspective on autonomy. Here are several key aspects to consider:\\n\\n1. **Ethical Frameworks**: Establishing clear ethical frameworks can help guide the development and deployment of AI. This includes principles such as fairness, transparency, accountability, and respect for human rights. By integrating ethical considerations into AI design from the outset, we can address potential biases and ensure that AI systems operate in ways that are aligned with societal values.\\n\\n2. **Human Oversight**: Maintaining human oversight in AI decision-making processes is critical. When AI systems are used for important decisions—such as in healthcare, criminal justice, or hiring—human operators should remain involved to provide context and judgment that AI cannot replicate. This approach preserves human autonomy and ensures accountability, as humans can critique or override AI recommendations.\\n\\n3. **Accountability Mechanisms**: Clearly defined accountability mechanisms are essential to ensure that individuals or organizations are held responsible for AI-driven outcomes. This includes establishing liability frameworks for AI decisions and ensuring that affected parties have avenues for redress. By clarifying who is accountable, we can reinforce responsible AI usage.\\n\\n4. **Stakeholder Engagement**: Engaging a diverse range of stakeholders, including ethicists, policymakers, technologists, and the communities impacted by AI, can foster a more comprehensive understanding of the implications of AI. This collaboration can help identify potential risks and benefits, guiding the responsible implementation of AI technologies.\\n\\n5. **Education and Awareness**: Promoting education and awareness about AI among the general population can empower individuals to make informed decisions and engage critically with AI technologies. Understanding AI's capabilities and limitations can enhance public discourse around its use and encourage responsible application.\\n\\n6. **Balancing Innovation and Regulation**: While fostering innovation is vital for leveraging the benefits of AI, it is equally important to establish regulatory frameworks that protect individuals and society from potential harms. Effective regulation can mitigate risks associated with AI while enabling its positive contributions to areas like healthcare, environmental monitoring, and education.\\n\\n7. **Iterative Improvement**: The field of AI is constantly evolving, which necessitates an iterative approach to ethics and accountability. Continuous assessment of AI systems after deployment allows for the identification of unforeseen ethical issues, facilitating ongoing improvements and adaptations to changing societal norms and values.\\n\\nIn summary, reconciling the ethical implications of AI with its benefits requires a holistic approach that involves transparent design practices, robust accountability structures, inclusive stakeholder engagement, and adaptable regulatory frameworks. By prioritizing ethical considerations alongside innovation, society can harness the potential of AI while minimizing risks and protecting decision-making autonomy.\", 'Reconciling the ethical implications of artificial intelligence with its immense potential benefits, particularly concerning decision-making autonomy and accountability, is one of the most pressing challenges of our time. It requires a multi-faceted approach that prioritizes human values, proactive governance, and continuous adaptation.\\n\\nHere\\'s how we can approach this reconciliation:\\n\\n---\\n\\n**1. Prioritize \"Ethics by Design\" and \"Responsible AI\" Principles:**\\n\\n*   **Integrate Ethical Considerations from the Outset:** Ethical principles (fairness, transparency, privacy, safety, accountability) should not be an afterthought but foundational to the AI system\\'s design, development, and deployment.\\n*   **Human-Centric AI:** Design AI to augment human capabilities, not replace human judgment, especially in critical decision-making contexts. The goal should be to empower humans, making them more effective and informed.\\n\\n**2. Foster Transparency and Explainability (XAI):**\\n\\n*   **Demystify AI Decisions:** For AI to be trusted, its decision-making processes need to be as understandable as possible. This is crucial for accountability. Where \"black box\" algorithms are used, surrogate models or post-hoc explanations can help.\\n*   **Contextual Explainability:** The level of explainability required depends on the context. A recommendation engine might need less explanation than an AI system approving a loan or diagnosing a medical condition.\\n*   **Traceability:** Ensure that AI decisions can be traced back to the data and logic that informed them, allowing for audits and debugging.\\n\\n**3. Implement Robust Human Oversight and \"Human-in-the-Loop\" Mechanisms:**\\n\\n*   **Varying Levels of Autonomy:** Not all AI systems need or should have full autonomy. Design systems with appropriate levels of human intervention, from \"human-on-the-loop\" (monitoring) to \"human-in-the-loop\" (approving, refining, overriding).\\n*   **Critical Decision Points:** For decisions with high stakes (e.g., medical diagnoses, legal judgments, military applications), human review and final approval should be mandatory. AI acts as an assistant or recommender, not the ultimate decision-maker.\\n*   **Empowering Human Judgment:** AI can process vast amounts of data and identify patterns, but humans bring contextual understanding, empathy, ethical reasoning, and the ability to handle novel situations that AI hasn\\'t been trained on.\\n\\n**4. Establish Clear Accountability Frameworks:**\\n\\n*   **Define Responsibility:** Clearly delineate who is responsible at each stage of the AI lifecycle: the data provider, the developer, the deployer, and the user.\\n*   **Algorithmic Accountability:** Develop legal and ethical frameworks that hold individuals and organizations accountable for the outcomes of AI systems, similar to how product liability works for physical goods.\\n*   **Liability Models:** Explore different liability models (e.g., strict liability for high-risk AI, shared liability). This often involves extending existing legal frameworks rather than creating entirely new ones.\\n*   **Independent Audits:** Mandate regular independent audits of AI systems for bias, performance, security, and adherence to ethical guidelines.\\n\\n**5. Address Bias and Fairness Proactively:**\\n\\n*   **Data Scrutiny:** Thoroughly audit training data for inherent biases (historical, societal, representation). \"Garbage in, garbage out\" is particularly true for AI.\\n*   **Algorithmic Fairness Metrics:** Develop and apply metrics to measure and mitigate bias in algorithms, ensuring equitable outcomes across different demographic groups.\\n*   **Continuous Monitoring:** AI systems can \"drift\" over time as they interact with new data. Continuous monitoring and retraining are essential to prevent the reintroduction or emergence of bias.\\n\\n**6. Develop Strong Governance and Regulatory Frameworks:**\\n\\n*   **International Cooperation:** AI\\'s global nature requires international collaboration to set common standards, best practices, and potentially treaties.\\n*   **Sector-Specific Regulations:** Different sectors (healthcare, finance, transportation, defense) will require tailored regulations due to their unique risks and benefits.\\n*   **Standardization Bodies:** Encourage the development of technical standards for AI safety, reliability, and interoperability.\\n*   **AI Ethics Boards/Committees:** Companies and governments should establish internal and external AI ethics boards to guide development, review deployments, and address concerns.\\n\\n**7. Foster Public Education and Dialogue:**\\n\\n*   **Literacy and Understanding:** Educate the public about AI\\'s capabilities, limitations, and potential impacts to build informed trust and address misconceptions.\\n*   **Participatory Design:** Involve diverse stakeholders (including affected communities) in the design and deployment process to ensure that AI systems meet societal needs and values.\\n*   **Ethical Debate:** Encourage ongoing public and academic discourse on complex AI ethics issues to evolve our understanding and find solutions.\\n\\n**8. Invest in Research on AI Safety and Alignment:**\\n\\n*   **Robustness and Reliability:** Research methods to make AI systems more robust, less susceptible to adversarial attacks, and predictable in their behavior.\\n*   **Value Alignment:** Invest in research to ensure that advanced AI systems are designed to align with human values and goals, especially as AI capabilities grow.\\n\\n---\\n\\n**In essence, reconciliation hinges on a dynamic balance:**\\n\\n*   **Embrace Benefits:** Leverage AI\\'s power to solve complex problems, enhance human capabilities, and drive societal progress (e.g., medical breakthroughs, climate modeling, personalized education).\\n*   **Mitigate Risks:** Proactively identify, understand, and address the ethical challenges, ensuring that AI serves humanity rather than undermining its values or autonomy.\\n\\nThe goal is not to stop AI progress but to guide it responsibly, ensuring that the technology\\'s benefits are widely shared and its risks are carefully managed through conscious design, robust governance, and a steadfast commitment to human dignity and accountability.', 'Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits requires a multifaceted approach that considers both the benefits and risks associated with AI decision-making autonomy and accountability. Here are some key considerations:\\n\\nBenefits of AI Decision-Making Autonomy:\\n\\n1. Improved accuracy: AI systems can process vast amounts of data quickly and accurately, reducing errors and increasing reliability.\\n2. Efficiency: AI can automate routine tasks, freeing human resources for more complex and creative work.\\n3. Personalization: AI can personalize experiences, products, and services based on individual preferences and behaviors.\\n\\nRisks associated with AI Decision-Making Autonomy:\\n\\n1. Bias and discrimination: AI systems may perpetuate existing biases if they are trained on biased data, leading to unfair outcomes.\\n2. Lack of transparency and accountability: AI decision-making processes can be opaque, making it difficult to understand the reasoning behind a particular decision.\\n3. Dependence on data quality: AI depends on high-quality data to function effectively, which may not always be available.\\n\\nAddressing Ethical Implications of AI Decision-Making Autonomy:\\n\\n1. **Data curation and validation**: Ensure that the data used to train AI systems is accurate, representative, and unbiased.\\n2. **Transparency and explainability**: Develop AI systems that provide transparent and interpretable explanations for their decision-making processes.\\n3. **Human oversight and review**: Implement human oversight and review mechanisms to detect and correct errors, biases, or unintended consequences.\\n4. **Regular testing and monitoring**: Regularly test and monitor AI systems for potential biases, errors, or performance degradation.\\n5. **Value alignment**: Ensure that AI systems are aligned with human values, such as fairness, respect, and dignity.\\n\\nAccountability in AI Decision-Making:\\n\\n1. **Design for accountability**: Incorporate accountability into the design of AI systems, including mechanisms for auditing, testing, and evaluation.\\n2. **Regulatory frameworks**: Establish regulatory frameworks that ensure companies prioritize transparency, accountability, and human oversight when developing and deploying AI systems.\\n3. **Public engagement and education**: Foster public awareness of AI-related issues and promote education on AI ethics, risks, and benefits.\\n\\nTo reconcile the ethical implications of AI with its potential benefits:\\n\\n1. Prioritize human values and well-being: Ensure that AI systems are designed to prioritize human values, dignity, and well-being.\\n2. Encourage open communication and collaboration: Promote open communication among stakeholders, including developers, policymakers, regulators, and civil society organizations.\\n3. Foster a culture of responsible innovation: Cultivate a culture of responsible innovation by prioritizing ethics, transparency, accountability, and social responsibility.\\n\\nUltimately, reconciling the ethical implications of AI with its potential benefits requires a proactive and multistakeholder approach that balances technological progress with social responsibility and human well-being.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits involves a multifaceted approach that emphasizes ethical design, accountability, and a balanced perspective on autonomy. Here are several key aspects to consider:\n",
      "\n",
      "1. **Ethical Frameworks**: Establishing clear ethical frameworks can help guide the development and deployment of AI. This includes principles such as fairness, transparency, accountability, and respect for human rights. By integrating ethical considerations into AI design from the outset, we can address potential biases and ensure that AI systems operate in ways that are aligned with societal values.\n",
      "\n",
      "2. **Human Oversight**: Maintaining human oversight in AI decision-making processes is critical. When AI systems are used for important decisions—such as in healthcare, criminal justice, or hiring—human operators should remain involved to provide context and judgment that AI cannot replicate. This approach preserves human autonomy and ensures accountability, as humans can critique or override AI recommendations.\n",
      "\n",
      "3. **Accountability Mechanisms**: Clearly defined accountability mechanisms are essential to ensure that individuals or organizations are held responsible for AI-driven outcomes. This includes establishing liability frameworks for AI decisions and ensuring that affected parties have avenues for redress. By clarifying who is accountable, we can reinforce responsible AI usage.\n",
      "\n",
      "4. **Stakeholder Engagement**: Engaging a diverse range of stakeholders, including ethicists, policymakers, technologists, and the communities impacted by AI, can foster a more comprehensive understanding of the implications of AI. This collaboration can help identify potential risks and benefits, guiding the responsible implementation of AI technologies.\n",
      "\n",
      "5. **Education and Awareness**: Promoting education and awareness about AI among the general population can empower individuals to make informed decisions and engage critically with AI technologies. Understanding AI's capabilities and limitations can enhance public discourse around its use and encourage responsible application.\n",
      "\n",
      "6. **Balancing Innovation and Regulation**: While fostering innovation is vital for leveraging the benefits of AI, it is equally important to establish regulatory frameworks that protect individuals and society from potential harms. Effective regulation can mitigate risks associated with AI while enabling its positive contributions to areas like healthcare, environmental monitoring, and education.\n",
      "\n",
      "7. **Iterative Improvement**: The field of AI is constantly evolving, which necessitates an iterative approach to ethics and accountability. Continuous assessment of AI systems after deployment allows for the identification of unforeseen ethical issues, facilitating ongoing improvements and adaptations to changing societal norms and values.\n",
      "\n",
      "In summary, reconciling the ethical implications of AI with its benefits requires a holistic approach that involves transparent design practices, robust accountability structures, inclusive stakeholder engagement, and adaptable regulatory frameworks. By prioritizing ethical considerations alongside innovation, society can harness the potential of AI while minimizing risks and protecting decision-making autonomy.\n",
      "Competitor: gemini-2.5-flash\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence with its immense potential benefits, particularly concerning decision-making autonomy and accountability, is one of the most pressing challenges of our time. It requires a multi-faceted approach that prioritizes human values, proactive governance, and continuous adaptation.\n",
      "\n",
      "Here's how we can approach this reconciliation:\n",
      "\n",
      "---\n",
      "\n",
      "**1. Prioritize \"Ethics by Design\" and \"Responsible AI\" Principles:**\n",
      "\n",
      "*   **Integrate Ethical Considerations from the Outset:** Ethical principles (fairness, transparency, privacy, safety, accountability) should not be an afterthought but foundational to the AI system's design, development, and deployment.\n",
      "*   **Human-Centric AI:** Design AI to augment human capabilities, not replace human judgment, especially in critical decision-making contexts. The goal should be to empower humans, making them more effective and informed.\n",
      "\n",
      "**2. Foster Transparency and Explainability (XAI):**\n",
      "\n",
      "*   **Demystify AI Decisions:** For AI to be trusted, its decision-making processes need to be as understandable as possible. This is crucial for accountability. Where \"black box\" algorithms are used, surrogate models or post-hoc explanations can help.\n",
      "*   **Contextual Explainability:** The level of explainability required depends on the context. A recommendation engine might need less explanation than an AI system approving a loan or diagnosing a medical condition.\n",
      "*   **Traceability:** Ensure that AI decisions can be traced back to the data and logic that informed them, allowing for audits and debugging.\n",
      "\n",
      "**3. Implement Robust Human Oversight and \"Human-in-the-Loop\" Mechanisms:**\n",
      "\n",
      "*   **Varying Levels of Autonomy:** Not all AI systems need or should have full autonomy. Design systems with appropriate levels of human intervention, from \"human-on-the-loop\" (monitoring) to \"human-in-the-loop\" (approving, refining, overriding).\n",
      "*   **Critical Decision Points:** For decisions with high stakes (e.g., medical diagnoses, legal judgments, military applications), human review and final approval should be mandatory. AI acts as an assistant or recommender, not the ultimate decision-maker.\n",
      "*   **Empowering Human Judgment:** AI can process vast amounts of data and identify patterns, but humans bring contextual understanding, empathy, ethical reasoning, and the ability to handle novel situations that AI hasn't been trained on.\n",
      "\n",
      "**4. Establish Clear Accountability Frameworks:**\n",
      "\n",
      "*   **Define Responsibility:** Clearly delineate who is responsible at each stage of the AI lifecycle: the data provider, the developer, the deployer, and the user.\n",
      "*   **Algorithmic Accountability:** Develop legal and ethical frameworks that hold individuals and organizations accountable for the outcomes of AI systems, similar to how product liability works for physical goods.\n",
      "*   **Liability Models:** Explore different liability models (e.g., strict liability for high-risk AI, shared liability). This often involves extending existing legal frameworks rather than creating entirely new ones.\n",
      "*   **Independent Audits:** Mandate regular independent audits of AI systems for bias, performance, security, and adherence to ethical guidelines.\n",
      "\n",
      "**5. Address Bias and Fairness Proactively:**\n",
      "\n",
      "*   **Data Scrutiny:** Thoroughly audit training data for inherent biases (historical, societal, representation). \"Garbage in, garbage out\" is particularly true for AI.\n",
      "*   **Algorithmic Fairness Metrics:** Develop and apply metrics to measure and mitigate bias in algorithms, ensuring equitable outcomes across different demographic groups.\n",
      "*   **Continuous Monitoring:** AI systems can \"drift\" over time as they interact with new data. Continuous monitoring and retraining are essential to prevent the reintroduction or emergence of bias.\n",
      "\n",
      "**6. Develop Strong Governance and Regulatory Frameworks:**\n",
      "\n",
      "*   **International Cooperation:** AI's global nature requires international collaboration to set common standards, best practices, and potentially treaties.\n",
      "*   **Sector-Specific Regulations:** Different sectors (healthcare, finance, transportation, defense) will require tailored regulations due to their unique risks and benefits.\n",
      "*   **Standardization Bodies:** Encourage the development of technical standards for AI safety, reliability, and interoperability.\n",
      "*   **AI Ethics Boards/Committees:** Companies and governments should establish internal and external AI ethics boards to guide development, review deployments, and address concerns.\n",
      "\n",
      "**7. Foster Public Education and Dialogue:**\n",
      "\n",
      "*   **Literacy and Understanding:** Educate the public about AI's capabilities, limitations, and potential impacts to build informed trust and address misconceptions.\n",
      "*   **Participatory Design:** Involve diverse stakeholders (including affected communities) in the design and deployment process to ensure that AI systems meet societal needs and values.\n",
      "*   **Ethical Debate:** Encourage ongoing public and academic discourse on complex AI ethics issues to evolve our understanding and find solutions.\n",
      "\n",
      "**8. Invest in Research on AI Safety and Alignment:**\n",
      "\n",
      "*   **Robustness and Reliability:** Research methods to make AI systems more robust, less susceptible to adversarial attacks, and predictable in their behavior.\n",
      "*   **Value Alignment:** Invest in research to ensure that advanced AI systems are designed to align with human values and goals, especially as AI capabilities grow.\n",
      "\n",
      "---\n",
      "\n",
      "**In essence, reconciliation hinges on a dynamic balance:**\n",
      "\n",
      "*   **Embrace Benefits:** Leverage AI's power to solve complex problems, enhance human capabilities, and drive societal progress (e.g., medical breakthroughs, climate modeling, personalized education).\n",
      "*   **Mitigate Risks:** Proactively identify, understand, and address the ethical challenges, ensuring that AI serves humanity rather than undermining its values or autonomy.\n",
      "\n",
      "The goal is not to stop AI progress but to guide it responsibly, ensuring that the technology's benefits are widely shared and its risks are carefully managed through conscious design, robust governance, and a steadfast commitment to human dignity and accountability.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits requires a multifaceted approach that considers both the benefits and risks associated with AI decision-making autonomy and accountability. Here are some key considerations:\n",
      "\n",
      "Benefits of AI Decision-Making Autonomy:\n",
      "\n",
      "1. Improved accuracy: AI systems can process vast amounts of data quickly and accurately, reducing errors and increasing reliability.\n",
      "2. Efficiency: AI can automate routine tasks, freeing human resources for more complex and creative work.\n",
      "3. Personalization: AI can personalize experiences, products, and services based on individual preferences and behaviors.\n",
      "\n",
      "Risks associated with AI Decision-Making Autonomy:\n",
      "\n",
      "1. Bias and discrimination: AI systems may perpetuate existing biases if they are trained on biased data, leading to unfair outcomes.\n",
      "2. Lack of transparency and accountability: AI decision-making processes can be opaque, making it difficult to understand the reasoning behind a particular decision.\n",
      "3. Dependence on data quality: AI depends on high-quality data to function effectively, which may not always be available.\n",
      "\n",
      "Addressing Ethical Implications of AI Decision-Making Autonomy:\n",
      "\n",
      "1. **Data curation and validation**: Ensure that the data used to train AI systems is accurate, representative, and unbiased.\n",
      "2. **Transparency and explainability**: Develop AI systems that provide transparent and interpretable explanations for their decision-making processes.\n",
      "3. **Human oversight and review**: Implement human oversight and review mechanisms to detect and correct errors, biases, or unintended consequences.\n",
      "4. **Regular testing and monitoring**: Regularly test and monitor AI systems for potential biases, errors, or performance degradation.\n",
      "5. **Value alignment**: Ensure that AI systems are aligned with human values, such as fairness, respect, and dignity.\n",
      "\n",
      "Accountability in AI Decision-Making:\n",
      "\n",
      "1. **Design for accountability**: Incorporate accountability into the design of AI systems, including mechanisms for auditing, testing, and evaluation.\n",
      "2. **Regulatory frameworks**: Establish regulatory frameworks that ensure companies prioritize transparency, accountability, and human oversight when developing and deploying AI systems.\n",
      "3. **Public engagement and education**: Foster public awareness of AI-related issues and promote education on AI ethics, risks, and benefits.\n",
      "\n",
      "To reconcile the ethical implications of AI with its potential benefits:\n",
      "\n",
      "1. Prioritize human values and well-being: Ensure that AI systems are designed to prioritize human values, dignity, and well-being.\n",
      "2. Encourage open communication and collaboration: Promote open communication among stakeholders, including developers, policymakers, regulators, and civil society organizations.\n",
      "3. Foster a culture of responsible innovation: Cultivate a culture of responsible innovation by prioritizing ethics, transparency, accountability, and social responsibility.\n",
      "\n",
      "Ultimately, reconciling the ethical implications of AI with its potential benefits requires a proactive and multistakeholder approach that balances technological progress with social responsibility and human well-being.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits involves a multifaceted approach that emphasizes ethical design, accountability, and a balanced perspective on autonomy. Here are several key aspects to consider:\n",
      "\n",
      "1. **Ethical Frameworks**: Establishing clear ethical frameworks can help guide the development and deployment of AI. This includes principles such as fairness, transparency, accountability, and respect for human rights. By integrating ethical considerations into AI design from the outset, we can address potential biases and ensure that AI systems operate in ways that are aligned with societal values.\n",
      "\n",
      "2. **Human Oversight**: Maintaining human oversight in AI decision-making processes is critical. When AI systems are used for important decisions—such as in healthcare, criminal justice, or hiring—human operators should remain involved to provide context and judgment that AI cannot replicate. This approach preserves human autonomy and ensures accountability, as humans can critique or override AI recommendations.\n",
      "\n",
      "3. **Accountability Mechanisms**: Clearly defined accountability mechanisms are essential to ensure that individuals or organizations are held responsible for AI-driven outcomes. This includes establishing liability frameworks for AI decisions and ensuring that affected parties have avenues for redress. By clarifying who is accountable, we can reinforce responsible AI usage.\n",
      "\n",
      "4. **Stakeholder Engagement**: Engaging a diverse range of stakeholders, including ethicists, policymakers, technologists, and the communities impacted by AI, can foster a more comprehensive understanding of the implications of AI. This collaboration can help identify potential risks and benefits, guiding the responsible implementation of AI technologies.\n",
      "\n",
      "5. **Education and Awareness**: Promoting education and awareness about AI among the general population can empower individuals to make informed decisions and engage critically with AI technologies. Understanding AI's capabilities and limitations can enhance public discourse around its use and encourage responsible application.\n",
      "\n",
      "6. **Balancing Innovation and Regulation**: While fostering innovation is vital for leveraging the benefits of AI, it is equally important to establish regulatory frameworks that protect individuals and society from potential harms. Effective regulation can mitigate risks associated with AI while enabling its positive contributions to areas like healthcare, environmental monitoring, and education.\n",
      "\n",
      "7. **Iterative Improvement**: The field of AI is constantly evolving, which necessitates an iterative approach to ethics and accountability. Continuous assessment of AI systems after deployment allows for the identification of unforeseen ethical issues, facilitating ongoing improvements and adaptations to changing societal norms and values.\n",
      "\n",
      "In summary, reconciling the ethical implications of AI with its benefits requires a holistic approach that involves transparent design practices, robust accountability structures, inclusive stakeholder engagement, and adaptable regulatory frameworks. By prioritizing ethical considerations alongside innovation, society can harness the potential of AI while minimizing risks and protecting decision-making autonomy.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence with its immense potential benefits, particularly concerning decision-making autonomy and accountability, is one of the most pressing challenges of our time. It requires a multi-faceted approach that prioritizes human values, proactive governance, and continuous adaptation.\n",
      "\n",
      "Here's how we can approach this reconciliation:\n",
      "\n",
      "---\n",
      "\n",
      "**1. Prioritize \"Ethics by Design\" and \"Responsible AI\" Principles:**\n",
      "\n",
      "*   **Integrate Ethical Considerations from the Outset:** Ethical principles (fairness, transparency, privacy, safety, accountability) should not be an afterthought but foundational to the AI system's design, development, and deployment.\n",
      "*   **Human-Centric AI:** Design AI to augment human capabilities, not replace human judgment, especially in critical decision-making contexts. The goal should be to empower humans, making them more effective and informed.\n",
      "\n",
      "**2. Foster Transparency and Explainability (XAI):**\n",
      "\n",
      "*   **Demystify AI Decisions:** For AI to be trusted, its decision-making processes need to be as understandable as possible. This is crucial for accountability. Where \"black box\" algorithms are used, surrogate models or post-hoc explanations can help.\n",
      "*   **Contextual Explainability:** The level of explainability required depends on the context. A recommendation engine might need less explanation than an AI system approving a loan or diagnosing a medical condition.\n",
      "*   **Traceability:** Ensure that AI decisions can be traced back to the data and logic that informed them, allowing for audits and debugging.\n",
      "\n",
      "**3. Implement Robust Human Oversight and \"Human-in-the-Loop\" Mechanisms:**\n",
      "\n",
      "*   **Varying Levels of Autonomy:** Not all AI systems need or should have full autonomy. Design systems with appropriate levels of human intervention, from \"human-on-the-loop\" (monitoring) to \"human-in-the-loop\" (approving, refining, overriding).\n",
      "*   **Critical Decision Points:** For decisions with high stakes (e.g., medical diagnoses, legal judgments, military applications), human review and final approval should be mandatory. AI acts as an assistant or recommender, not the ultimate decision-maker.\n",
      "*   **Empowering Human Judgment:** AI can process vast amounts of data and identify patterns, but humans bring contextual understanding, empathy, ethical reasoning, and the ability to handle novel situations that AI hasn't been trained on.\n",
      "\n",
      "**4. Establish Clear Accountability Frameworks:**\n",
      "\n",
      "*   **Define Responsibility:** Clearly delineate who is responsible at each stage of the AI lifecycle: the data provider, the developer, the deployer, and the user.\n",
      "*   **Algorithmic Accountability:** Develop legal and ethical frameworks that hold individuals and organizations accountable for the outcomes of AI systems, similar to how product liability works for physical goods.\n",
      "*   **Liability Models:** Explore different liability models (e.g., strict liability for high-risk AI, shared liability). This often involves extending existing legal frameworks rather than creating entirely new ones.\n",
      "*   **Independent Audits:** Mandate regular independent audits of AI systems for bias, performance, security, and adherence to ethical guidelines.\n",
      "\n",
      "**5. Address Bias and Fairness Proactively:**\n",
      "\n",
      "*   **Data Scrutiny:** Thoroughly audit training data for inherent biases (historical, societal, representation). \"Garbage in, garbage out\" is particularly true for AI.\n",
      "*   **Algorithmic Fairness Metrics:** Develop and apply metrics to measure and mitigate bias in algorithms, ensuring equitable outcomes across different demographic groups.\n",
      "*   **Continuous Monitoring:** AI systems can \"drift\" over time as they interact with new data. Continuous monitoring and retraining are essential to prevent the reintroduction or emergence of bias.\n",
      "\n",
      "**6. Develop Strong Governance and Regulatory Frameworks:**\n",
      "\n",
      "*   **International Cooperation:** AI's global nature requires international collaboration to set common standards, best practices, and potentially treaties.\n",
      "*   **Sector-Specific Regulations:** Different sectors (healthcare, finance, transportation, defense) will require tailored regulations due to their unique risks and benefits.\n",
      "*   **Standardization Bodies:** Encourage the development of technical standards for AI safety, reliability, and interoperability.\n",
      "*   **AI Ethics Boards/Committees:** Companies and governments should establish internal and external AI ethics boards to guide development, review deployments, and address concerns.\n",
      "\n",
      "**7. Foster Public Education and Dialogue:**\n",
      "\n",
      "*   **Literacy and Understanding:** Educate the public about AI's capabilities, limitations, and potential impacts to build informed trust and address misconceptions.\n",
      "*   **Participatory Design:** Involve diverse stakeholders (including affected communities) in the design and deployment process to ensure that AI systems meet societal needs and values.\n",
      "*   **Ethical Debate:** Encourage ongoing public and academic discourse on complex AI ethics issues to evolve our understanding and find solutions.\n",
      "\n",
      "**8. Invest in Research on AI Safety and Alignment:**\n",
      "\n",
      "*   **Robustness and Reliability:** Research methods to make AI systems more robust, less susceptible to adversarial attacks, and predictable in their behavior.\n",
      "*   **Value Alignment:** Invest in research to ensure that advanced AI systems are designed to align with human values and goals, especially as AI capabilities grow.\n",
      "\n",
      "---\n",
      "\n",
      "**In essence, reconciliation hinges on a dynamic balance:**\n",
      "\n",
      "*   **Embrace Benefits:** Leverage AI's power to solve complex problems, enhance human capabilities, and drive societal progress (e.g., medical breakthroughs, climate modeling, personalized education).\n",
      "*   **Mitigate Risks:** Proactively identify, understand, and address the ethical challenges, ensuring that AI serves humanity rather than undermining its values or autonomy.\n",
      "\n",
      "The goal is not to stop AI progress but to guide it responsibly, ensuring that the technology's benefits are widely shared and its risks are carefully managed through conscious design, robust governance, and a steadfast commitment to human dignity and accountability.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits requires a multifaceted approach that considers both the benefits and risks associated with AI decision-making autonomy and accountability. Here are some key considerations:\n",
      "\n",
      "Benefits of AI Decision-Making Autonomy:\n",
      "\n",
      "1. Improved accuracy: AI systems can process vast amounts of data quickly and accurately, reducing errors and increasing reliability.\n",
      "2. Efficiency: AI can automate routine tasks, freeing human resources for more complex and creative work.\n",
      "3. Personalization: AI can personalize experiences, products, and services based on individual preferences and behaviors.\n",
      "\n",
      "Risks associated with AI Decision-Making Autonomy:\n",
      "\n",
      "1. Bias and discrimination: AI systems may perpetuate existing biases if they are trained on biased data, leading to unfair outcomes.\n",
      "2. Lack of transparency and accountability: AI decision-making processes can be opaque, making it difficult to understand the reasoning behind a particular decision.\n",
      "3. Dependence on data quality: AI depends on high-quality data to function effectively, which may not always be available.\n",
      "\n",
      "Addressing Ethical Implications of AI Decision-Making Autonomy:\n",
      "\n",
      "1. **Data curation and validation**: Ensure that the data used to train AI systems is accurate, representative, and unbiased.\n",
      "2. **Transparency and explainability**: Develop AI systems that provide transparent and interpretable explanations for their decision-making processes.\n",
      "3. **Human oversight and review**: Implement human oversight and review mechanisms to detect and correct errors, biases, or unintended consequences.\n",
      "4. **Regular testing and monitoring**: Regularly test and monitor AI systems for potential biases, errors, or performance degradation.\n",
      "5. **Value alignment**: Ensure that AI systems are aligned with human values, such as fairness, respect, and dignity.\n",
      "\n",
      "Accountability in AI Decision-Making:\n",
      "\n",
      "1. **Design for accountability**: Incorporate accountability into the design of AI systems, including mechanisms for auditing, testing, and evaluation.\n",
      "2. **Regulatory frameworks**: Establish regulatory frameworks that ensure companies prioritize transparency, accountability, and human oversight when developing and deploying AI systems.\n",
      "3. **Public engagement and education**: Foster public awareness of AI-related issues and promote education on AI ethics, risks, and benefits.\n",
      "\n",
      "To reconcile the ethical implications of AI with its potential benefits:\n",
      "\n",
      "1. Prioritize human values and well-being: Ensure that AI systems are designed to prioritize human values, dignity, and well-being.\n",
      "2. Encourage open communication and collaboration: Promote open communication among stakeholders, including developers, policymakers, regulators, and civil society organizations.\n",
      "3. Foster a culture of responsible innovation: Cultivate a culture of responsible innovation by prioritizing ethics, transparency, accountability, and social responsibility.\n",
      "\n",
      "Ultimately, reconciling the ethical implications of AI with its potential benefits requires a proactive and multistakeholder approach that balances technological progress with social responsibility and human well-being.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 3 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How do you reconcile the ethical implications of artificial intelligence with the potential benefits it brings to society, particularly in terms of decision-making autonomy and accountability?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits involves a multifaceted approach that emphasizes ethical design, accountability, and a balanced perspective on autonomy. Here are several key aspects to consider:\n",
      "\n",
      "1. **Ethical Frameworks**: Establishing clear ethical frameworks can help guide the development and deployment of AI. This includes principles such as fairness, transparency, accountability, and respect for human rights. By integrating ethical considerations into AI design from the outset, we can address potential biases and ensure that AI systems operate in ways that are aligned with societal values.\n",
      "\n",
      "2. **Human Oversight**: Maintaining human oversight in AI decision-making processes is critical. When AI systems are used for important decisions—such as in healthcare, criminal justice, or hiring—human operators should remain involved to provide context and judgment that AI cannot replicate. This approach preserves human autonomy and ensures accountability, as humans can critique or override AI recommendations.\n",
      "\n",
      "3. **Accountability Mechanisms**: Clearly defined accountability mechanisms are essential to ensure that individuals or organizations are held responsible for AI-driven outcomes. This includes establishing liability frameworks for AI decisions and ensuring that affected parties have avenues for redress. By clarifying who is accountable, we can reinforce responsible AI usage.\n",
      "\n",
      "4. **Stakeholder Engagement**: Engaging a diverse range of stakeholders, including ethicists, policymakers, technologists, and the communities impacted by AI, can foster a more comprehensive understanding of the implications of AI. This collaboration can help identify potential risks and benefits, guiding the responsible implementation of AI technologies.\n",
      "\n",
      "5. **Education and Awareness**: Promoting education and awareness about AI among the general population can empower individuals to make informed decisions and engage critically with AI technologies. Understanding AI's capabilities and limitations can enhance public discourse around its use and encourage responsible application.\n",
      "\n",
      "6. **Balancing Innovation and Regulation**: While fostering innovation is vital for leveraging the benefits of AI, it is equally important to establish regulatory frameworks that protect individuals and society from potential harms. Effective regulation can mitigate risks associated with AI while enabling its positive contributions to areas like healthcare, environmental monitoring, and education.\n",
      "\n",
      "7. **Iterative Improvement**: The field of AI is constantly evolving, which necessitates an iterative approach to ethics and accountability. Continuous assessment of AI systems after deployment allows for the identification of unforeseen ethical issues, facilitating ongoing improvements and adaptations to changing societal norms and values.\n",
      "\n",
      "In summary, reconciling the ethical implications of AI with its benefits requires a holistic approach that involves transparent design practices, robust accountability structures, inclusive stakeholder engagement, and adaptable regulatory frameworks. By prioritizing ethical considerations alongside innovation, society can harness the potential of AI while minimizing risks and protecting decision-making autonomy.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence with its immense potential benefits, particularly concerning decision-making autonomy and accountability, is one of the most pressing challenges of our time. It requires a multi-faceted approach that prioritizes human values, proactive governance, and continuous adaptation.\n",
      "\n",
      "Here's how we can approach this reconciliation:\n",
      "\n",
      "---\n",
      "\n",
      "**1. Prioritize \"Ethics by Design\" and \"Responsible AI\" Principles:**\n",
      "\n",
      "*   **Integrate Ethical Considerations from the Outset:** Ethical principles (fairness, transparency, privacy, safety, accountability) should not be an afterthought but foundational to the AI system's design, development, and deployment.\n",
      "*   **Human-Centric AI:** Design AI to augment human capabilities, not replace human judgment, especially in critical decision-making contexts. The goal should be to empower humans, making them more effective and informed.\n",
      "\n",
      "**2. Foster Transparency and Explainability (XAI):**\n",
      "\n",
      "*   **Demystify AI Decisions:** For AI to be trusted, its decision-making processes need to be as understandable as possible. This is crucial for accountability. Where \"black box\" algorithms are used, surrogate models or post-hoc explanations can help.\n",
      "*   **Contextual Explainability:** The level of explainability required depends on the context. A recommendation engine might need less explanation than an AI system approving a loan or diagnosing a medical condition.\n",
      "*   **Traceability:** Ensure that AI decisions can be traced back to the data and logic that informed them, allowing for audits and debugging.\n",
      "\n",
      "**3. Implement Robust Human Oversight and \"Human-in-the-Loop\" Mechanisms:**\n",
      "\n",
      "*   **Varying Levels of Autonomy:** Not all AI systems need or should have full autonomy. Design systems with appropriate levels of human intervention, from \"human-on-the-loop\" (monitoring) to \"human-in-the-loop\" (approving, refining, overriding).\n",
      "*   **Critical Decision Points:** For decisions with high stakes (e.g., medical diagnoses, legal judgments, military applications), human review and final approval should be mandatory. AI acts as an assistant or recommender, not the ultimate decision-maker.\n",
      "*   **Empowering Human Judgment:** AI can process vast amounts of data and identify patterns, but humans bring contextual understanding, empathy, ethical reasoning, and the ability to handle novel situations that AI hasn't been trained on.\n",
      "\n",
      "**4. Establish Clear Accountability Frameworks:**\n",
      "\n",
      "*   **Define Responsibility:** Clearly delineate who is responsible at each stage of the AI lifecycle: the data provider, the developer, the deployer, and the user.\n",
      "*   **Algorithmic Accountability:** Develop legal and ethical frameworks that hold individuals and organizations accountable for the outcomes of AI systems, similar to how product liability works for physical goods.\n",
      "*   **Liability Models:** Explore different liability models (e.g., strict liability for high-risk AI, shared liability). This often involves extending existing legal frameworks rather than creating entirely new ones.\n",
      "*   **Independent Audits:** Mandate regular independent audits of AI systems for bias, performance, security, and adherence to ethical guidelines.\n",
      "\n",
      "**5. Address Bias and Fairness Proactively:**\n",
      "\n",
      "*   **Data Scrutiny:** Thoroughly audit training data for inherent biases (historical, societal, representation). \"Garbage in, garbage out\" is particularly true for AI.\n",
      "*   **Algorithmic Fairness Metrics:** Develop and apply metrics to measure and mitigate bias in algorithms, ensuring equitable outcomes across different demographic groups.\n",
      "*   **Continuous Monitoring:** AI systems can \"drift\" over time as they interact with new data. Continuous monitoring and retraining are essential to prevent the reintroduction or emergence of bias.\n",
      "\n",
      "**6. Develop Strong Governance and Regulatory Frameworks:**\n",
      "\n",
      "*   **International Cooperation:** AI's global nature requires international collaboration to set common standards, best practices, and potentially treaties.\n",
      "*   **Sector-Specific Regulations:** Different sectors (healthcare, finance, transportation, defense) will require tailored regulations due to their unique risks and benefits.\n",
      "*   **Standardization Bodies:** Encourage the development of technical standards for AI safety, reliability, and interoperability.\n",
      "*   **AI Ethics Boards/Committees:** Companies and governments should establish internal and external AI ethics boards to guide development, review deployments, and address concerns.\n",
      "\n",
      "**7. Foster Public Education and Dialogue:**\n",
      "\n",
      "*   **Literacy and Understanding:** Educate the public about AI's capabilities, limitations, and potential impacts to build informed trust and address misconceptions.\n",
      "*   **Participatory Design:** Involve diverse stakeholders (including affected communities) in the design and deployment process to ensure that AI systems meet societal needs and values.\n",
      "*   **Ethical Debate:** Encourage ongoing public and academic discourse on complex AI ethics issues to evolve our understanding and find solutions.\n",
      "\n",
      "**8. Invest in Research on AI Safety and Alignment:**\n",
      "\n",
      "*   **Robustness and Reliability:** Research methods to make AI systems more robust, less susceptible to adversarial attacks, and predictable in their behavior.\n",
      "*   **Value Alignment:** Invest in research to ensure that advanced AI systems are designed to align with human values and goals, especially as AI capabilities grow.\n",
      "\n",
      "---\n",
      "\n",
      "**In essence, reconciliation hinges on a dynamic balance:**\n",
      "\n",
      "*   **Embrace Benefits:** Leverage AI's power to solve complex problems, enhance human capabilities, and drive societal progress (e.g., medical breakthroughs, climate modeling, personalized education).\n",
      "*   **Mitigate Risks:** Proactively identify, understand, and address the ethical challenges, ensuring that AI serves humanity rather than undermining its values or autonomy.\n",
      "\n",
      "The goal is not to stop AI progress but to guide it responsibly, ensuring that the technology's benefits are widely shared and its risks are carefully managed through conscious design, robust governance, and a steadfast commitment to human dignity and accountability.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) with its potential benefits requires a multifaceted approach that considers both the benefits and risks associated with AI decision-making autonomy and accountability. Here are some key considerations:\n",
      "\n",
      "Benefits of AI Decision-Making Autonomy:\n",
      "\n",
      "1. Improved accuracy: AI systems can process vast amounts of data quickly and accurately, reducing errors and increasing reliability.\n",
      "2. Efficiency: AI can automate routine tasks, freeing human resources for more complex and creative work.\n",
      "3. Personalization: AI can personalize experiences, products, and services based on individual preferences and behaviors.\n",
      "\n",
      "Risks associated with AI Decision-Making Autonomy:\n",
      "\n",
      "1. Bias and discrimination: AI systems may perpetuate existing biases if they are trained on biased data, leading to unfair outcomes.\n",
      "2. Lack of transparency and accountability: AI decision-making processes can be opaque, making it difficult to understand the reasoning behind a particular decision.\n",
      "3. Dependence on data quality: AI depends on high-quality data to function effectively, which may not always be available.\n",
      "\n",
      "Addressing Ethical Implications of AI Decision-Making Autonomy:\n",
      "\n",
      "1. **Data curation and validation**: Ensure that the data used to train AI systems is accurate, representative, and unbiased.\n",
      "2. **Transparency and explainability**: Develop AI systems that provide transparent and interpretable explanations for their decision-making processes.\n",
      "3. **Human oversight and review**: Implement human oversight and review mechanisms to detect and correct errors, biases, or unintended consequences.\n",
      "4. **Regular testing and monitoring**: Regularly test and monitor AI systems for potential biases, errors, or performance degradation.\n",
      "5. **Value alignment**: Ensure that AI systems are aligned with human values, such as fairness, respect, and dignity.\n",
      "\n",
      "Accountability in AI Decision-Making:\n",
      "\n",
      "1. **Design for accountability**: Incorporate accountability into the design of AI systems, including mechanisms for auditing, testing, and evaluation.\n",
      "2. **Regulatory frameworks**: Establish regulatory frameworks that ensure companies prioritize transparency, accountability, and human oversight when developing and deploying AI systems.\n",
      "3. **Public engagement and education**: Foster public awareness of AI-related issues and promote education on AI ethics, risks, and benefits.\n",
      "\n",
      "To reconcile the ethical implications of AI with its potential benefits:\n",
      "\n",
      "1. Prioritize human values and well-being: Ensure that AI systems are designed to prioritize human values, dignity, and well-being.\n",
      "2. Encourage open communication and collaboration: Promote open communication among stakeholders, including developers, policymakers, regulators, and civil society organizations.\n",
      "3. Foster a culture of responsible innovation: Cultivate a culture of responsible innovation by prioritizing ethics, transparency, accountability, and social responsibility.\n",
      "\n",
      "Ultimately, reconciling the ethical implications of AI with its potential benefits requires a proactive and multistakeholder approach that balances technological progress with social responsibility and human well-being.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"1\", \"3\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.5-flash\n",
      "Rank 2: gpt-4o-mini\n",
      "Rank 3: llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
